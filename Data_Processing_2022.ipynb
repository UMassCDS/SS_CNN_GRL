{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update dataset name as needed\n",
    "\n",
    "EXPERIMENT = \"sand\"\n",
    "# EXPERIMENT = \"clay\"\n",
    "EXPERIMENT = \"sand_128px\"\n",
    "\n",
    "# RAW_DATA_FOLDER_CLAY = '../'\n",
    "# RAW_MAT_FOLDER_CLAY = RAW_DATA_FOLDER_CLAY + 'raw_mat_new_clay/'\n",
    "# RAW_NPY_FOLDER_CLAY = RAW_DATA_FOLDER_CLAY + 'raw_npy_clay/'\n",
    "# NPY_FOLDER_CLAY = '../processed_input_data_clay/'\n",
    "\n",
    "RAW_DATA_FOLDER = '../'\n",
    "RAW_MAT_FOLDER = RAW_DATA_FOLDER + 'raw_mat_new_' + EXPERIMENT + '/'\n",
    "RAW_NPY_FOLDER = RAW_DATA_FOLDER + 'raw_npy_' + EXPERIMENT + '/'\n",
    "NPY_FOLDER = '../processed_input_data_' + EXPERIMENT + '/'\n",
    "\n",
    "#split data\n",
    "## attribute all exp_1 to training\n",
    "## attribute 2 windows (split_ratio) from exp_2 and exp_3 to training\n",
    "## the rest were randomly used for either eval and train. \n",
    "ML_exp = 'split_master'\n",
    "split_ratio=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXP_LIST contains a list of raw experiment XXX.mat files \n",
    "#Format: raw .mat --> raw .npy --> sliced & labeled .npy \n",
    "\n",
    "if EXPERIMENT == \"clay\":\n",
    "# Experiments list for Clay\n",
    "    EXP_LIST = ['EB_025_1','EB_025_2','EB_025_3',\n",
    "            'EB_050_1','EB_050_2','EB_050_3',\n",
    "            'EB_150_1','EB_150_2','EB_150_3',\n",
    "            'PP_025_1','PP_025_2',\n",
    "            'PP_050_1','PP_050_2',\n",
    "            'PP_100_1','PP_100_2',\n",
    "            'PP_150_1']\n",
    "elif EXPERIMENT == \"sand\":\n",
    "# Experiments list for Sand\n",
    "    EXP_LIST = ['E355_64px_forCNN',\n",
    "    'E339_64px_forCNN',\n",
    "    'E280_64px_forCNN',\n",
    "    'E366_64px_forCNN',\n",
    "    'E342_64px_forCNN',\n",
    "    'E340_64px_forCNN',\n",
    "    'E364_64px_forCNN',\n",
    "    'E347_64px_forCNN',\n",
    "    'E346_64px_forCNN',\n",
    "    'E341_64px_forCNN',\n",
    "    'E365_64px_forCNN',\n",
    "    'E338_64px_forCNN',\n",
    "    'E345_64px_forCNN',\n",
    "    'E363_64px_forCNN',\n",
    "    'E368_64px_forCNN',\n",
    "    'E369_64px_forCNN',\n",
    "    'E458_64px_forCNN',\n",
    "    'E459_64px_forCNN',\n",
    "    'E463_64px_forCNN',\n",
    "    'E464_64px_forCNN',\n",
    "    'E499_64px_forCNN']\n",
    "else:\n",
    "# Experiments list for Sand_128px\n",
    "    EXP_LIST = ['E355_128px_forCNN',\n",
    "    'E339_128px_forCNN',\n",
    "    'E280_128px_forCNN',\n",
    "    'E366_128px_forCNN',\n",
    "    'E342_128px_forCNN',\n",
    "    'E340_128px_forCNN',\n",
    "    'E364_128px_forCNN',\n",
    "    'E347_128px_forCNN',\n",
    "    'E346_128px_forCNN',\n",
    "    'E341_128px_forCNN',\n",
    "    'E365_128px_forCNN',\n",
    "    'E338_128px_forCNN',\n",
    "    'E345_128px_forCNN',\n",
    "    'E363_128px_forCNN',\n",
    "    'E368_128px_forCNN',\n",
    "    'E369_128px_forCNN',\n",
    "    'E458_128px_forCNN',\n",
    "    'E459_128px_forCNN',\n",
    "    'E463_128px_forCNN',\n",
    "    'E464_128px_forCNN',\n",
    "    'E499_128px_forCNN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functions to generate.npy files from mat files \n",
    "\n",
    "\n",
    "def create_npy(exp):\n",
    "    matlab_data_path = RAW_MAT_FOLDER + str(exp) + '.mat' \n",
    "    npy_data_path = RAW_NPY_FOLDER + str(exp) +'data.npy'\n",
    "    npy_label_path = RAW_NPY_FOLDER + str(exp) +'label.npy'\n",
    "    npy_para_path = RAW_NPY_FOLDER + str(exp) +'para.npy'\n",
    "    \n",
    "    if not os.path.exists(RAW_NPY_FOLDER):\n",
    "        os.mkdir(RAW_NPY_FOLDER)\n",
    "    if os.path.exists(npy_data_path):\n",
    "        raise Exception(\"raw .npy file already exist\")\n",
    "    else:  \n",
    "        data = sio.loadmat(matlab_data_path) [\"fault_map\"]  \n",
    "        label = sio.loadmat(matlab_data_path) [\"label\"]\n",
    "        \n",
    "        WW = sio.loadmat(matlab_data_path) [\"windowWidth\"]\n",
    "        overlap = sio.loadmat(matlab_data_path) [\"overlap\"]\n",
    "        \n",
    "        slice_param = [0 for a in range(4)]\n",
    "        slice_param[3] = WW[0,0]\n",
    "        slice_param[2] = 2* slice_param[3]\n",
    "        slice_param[1] = slice_param[3]- overlap[0,0]\n",
    "        slice_param[0] = 0\n",
    "        \n",
    "        # report sizes and save data, parameters and label\n",
    "        print(data.shape)\n",
    "        print(label.shape)\n",
    "        print(slice_param)\n",
    "        np.save(npy_data_path, data)\n",
    "        np.save(npy_label_path, label)\n",
    "        np.save(npy_para_path, slice_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E355_128px_forCNN\n",
      "(256, 434, 79)\n",
      "(4, 79, 2)\n",
      "[0, 102, 256, 128]\n",
      "E339_128px_forCNN\n",
      "(256, 944, 63)\n",
      "(9, 63, 2)\n",
      "[0, 102, 256, 128]\n",
      "E280_128px_forCNN\n",
      "(256, 740, 61)\n",
      "(7, 61, 2)\n",
      "[0, 102, 256, 128]\n",
      "E366_128px_forCNN\n",
      "(256, 1556, 42)\n",
      "(15, 42, 2)\n",
      "[0, 102, 256, 128]\n",
      "E342_128px_forCNN\n",
      "(256, 1556, 42)\n",
      "(15, 42, 2)\n",
      "[0, 102, 256, 128]\n",
      "E340_128px_forCNN\n",
      "(256, 1148, 55)\n",
      "(11, 55, 2)\n",
      "[0, 102, 256, 128]\n",
      "E364_128px_forCNN\n",
      "(256, 2474, 48)\n",
      "(24, 48, 2)\n",
      "[0, 102, 256, 128]\n",
      "E347_128px_forCNN\n",
      "(256, 536, 62)\n",
      "(5, 62, 2)\n",
      "[0, 102, 256, 128]\n",
      "E346_128px_forCNN\n",
      "(256, 1046, 61)\n",
      "(10, 61, 2)\n",
      "[0, 102, 256, 128]\n",
      "E341_128px_forCNN\n",
      "(256, 2474, 49)\n",
      "(24, 49, 2)\n",
      "[0, 102, 256, 128]\n",
      "E365_128px_forCNN\n",
      "(256, 1148, 55)\n",
      "(11, 55, 2)\n",
      "[0, 102, 256, 128]\n",
      "E338_128px_forCNN\n",
      "(256, 434, 82)\n",
      "(4, 82, 2)\n",
      "[0, 102, 256, 128]\n",
      "E345_128px_forCNN\n",
      "(256, 536, 76)\n",
      "(5, 76, 2)\n",
      "[0, 102, 256, 128]\n",
      "E363_128px_forCNN\n",
      "(256, 536, 66)\n",
      "(5, 66, 2)\n",
      "[0, 102, 256, 128]\n",
      "E368_128px_forCNN\n",
      "(256, 740, 66)\n",
      "(7, 66, 2)\n",
      "[0, 102, 256, 128]\n",
      "E369_128px_forCNN\n",
      "(256, 944, 57)\n",
      "(9, 57, 2)\n",
      "[0, 102, 256, 128]\n",
      "E458_128px_forCNN\n",
      "(256, 638, 99)\n",
      "(6, 99, 2)\n",
      "[0, 102, 256, 128]\n",
      "E459_128px_forCNN\n",
      "(256, 638, 107)\n",
      "(6, 107, 2)\n",
      "[0, 102, 256, 128]\n",
      "E463_128px_forCNN\n",
      "(256, 536, 98)\n",
      "(5, 98, 2)\n",
      "[0, 102, 256, 128]\n",
      "E464_128px_forCNN\n",
      "(256, 434, 99)\n",
      "(4, 99, 2)\n",
      "[0, 102, 256, 128]\n",
      "E499_128px_forCNN\n",
      "(256, 536, 60)\n",
      "(5, 60, 2)\n",
      "[0, 102, 256, 128]\n"
     ]
    }
   ],
   "source": [
    "# Generate and save raw_npy for list of experiment\n",
    "# Only need to run once! \n",
    "\n",
    "for e in EXP_LIST:\n",
    "    print(e)\n",
    "    create_npy(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function creates slices of each fault map\n",
    "def slicing_hw(RAW_NPY_FOLDER, exp): \n",
    "    npy_data_path = RAW_NPY_FOLDER + str(exp) +'data.npy'\n",
    "    npy_para_path = RAW_NPY_FOLDER + str(exp) +'para.npy'\n",
    "    \n",
    "    data = np.load(npy_data_path)\n",
    "    print(data.shape)\n",
    "    slice_param = np.load(npy_para_path)\n",
    "    \n",
    "    #data has dimension of (x, y, cfuv, t)\n",
    "    width_tot = data.shape[1]\n",
    "    t_tot = data.shape[2]\n",
    "    #print(width_tot,t_tot)\n",
    "    \n",
    "    #unpack slice_param into initial_index, strike_lenght, window_H and window_W\n",
    "    ii = slice_param[0]\n",
    "    strike = slice_param[1]\n",
    "    H = slice_param[2]\n",
    "    W = slice_param[3]\n",
    "    print(ii,strike,H,W)\n",
    "    \n",
    "    # set number of windows and slice data and label \n",
    "    num_win = 1 + (width_tot - W)//strike   \n",
    "    \n",
    "    data_hw = []\n",
    "    w_idx = np.arange(num_win)\n",
    "    for w_i in w_idx:\n",
    "        left_win = w_i*strike\n",
    "        #print(left_win)\n",
    "        data_hwi = data[:,left_win:left_win+W]\n",
    "        #data_hw is a list of tuples (number of tuples = num_win)\n",
    "        #first element of tuple has a shape = (WindowHeight, WindowWidth, numFrames)\n",
    "        #second element of tuple is the w_idx\n",
    "        data_hw.append((data_hwi, w_i))\n",
    "\n",
    "    print(\"Data_slice_shape =\", data_hw[0][0].shape)\n",
    "    return data_hw, num_win, t_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function gathers the label information and saves with slices to be read for dividing into \n",
    "#training, eval and testing data sets.\n",
    "def data_slice_KE(RAW_NPY_FOLDER, NPY_FOLDER, exp):\n",
    "    \n",
    "    #set file location for \n",
    "    npy_exp_folder_path = NPY_FOLDER + 'slice_npy/' + str(exp)\n",
    "    master_folder_path = NPY_FOLDER + 'file_master/'\n",
    "    \n",
    "    #need to grab the KE labels\n",
    "    npy_label_path = RAW_NPY_FOLDER + str(exp) +'label.npy'\n",
    "    label = np.load(npy_label_path)\n",
    "    #print('label', label.shape)\n",
    "    \n",
    "    if os.path.exists(npy_exp_folder_path):\n",
    "        raise Exception(\"slice_exp.npy already exist\")\n",
    "    else: \n",
    "        os.makedirs(npy_exp_folder_path)\n",
    "        if not os.path.exists(master_folder_path): \n",
    "            os.makedirs(master_folder_path)     \n",
    "    \n",
    "    #slice the fault_map\n",
    "    data_hw, num_win, t_tot = slicing_hw(RAW_NPY_FOLDER, exp)\n",
    "    \n",
    "    w_idx = np.arange(num_win)\n",
    "    file_master = []\n",
    "    \n",
    "    #looping through all windows and times \n",
    "    for w_i in w_idx: \n",
    "        for t_i in range(t_tot):\n",
    "            #unpacking data_hw\n",
    "            data_f, win = data_hw[w_i]\n",
    "            #print(win)\n",
    "        \n",
    "            #only process slice with non-zero fault traces\n",
    "            if np.sum(data_f[:,:,t_i]) != 0:\n",
    "                \n",
    "                #The first array of the label array are the std and the second array is the KE\n",
    "                label_KE = label[w_i,t_i,1]\n",
    "                label_SD = label[w_i,t_i,0]\n",
    "                #print(w_i,t_i,label_KE,label_SD)\n",
    "                \n",
    "                name_path = '/' + \"{:.4f}\".format(label_KE) + '_' + \"{:.4f}\".format(label_SD) + '_win_' + str(\n",
    "                        win) + '_t_' + str('{:03d}'.format(t_i)) + '_' + str(exp) + '_cfuv.npy'\n",
    "                # save sliced and labeled dataset in slice_npy folder\n",
    "                np.save(npy_exp_folder_path + name_path, data_f[:,:,t_i])\n",
    "                \n",
    "                # add to file master\n",
    "                file_master.append(str(exp) + name_path)          \n",
    "    \n",
    "    master_data_path = master_folder_path + str(exp) + \".txt\"\n",
    "    print('non_zero_slice =', len(file_master))\n",
    "    np.savetxt(master_data_path, file_master, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 434, 79)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 79)\n",
      "non_zero_slice = 283\n",
      "(256, 944, 63)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 63)\n",
      "non_zero_slice = 435\n",
      "(256, 740, 61)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 61)\n",
      "non_zero_slice = 328\n",
      "(256, 1556, 42)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 42)\n",
      "non_zero_slice = 504\n",
      "(256, 1556, 42)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 42)\n",
      "non_zero_slice = 474\n",
      "(256, 1148, 55)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 55)\n",
      "non_zero_slice = 484\n",
      "(256, 2474, 48)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 48)\n",
      "non_zero_slice = 949\n",
      "(256, 536, 62)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 62)\n",
      "non_zero_slice = 254\n",
      "(256, 1046, 61)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 61)\n",
      "non_zero_slice = 503\n",
      "(256, 2474, 49)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 49)\n",
      "non_zero_slice = 857\n",
      "(256, 1148, 55)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 55)\n",
      "non_zero_slice = 491\n",
      "(256, 434, 82)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 82)\n",
      "non_zero_slice = 259\n",
      "(256, 536, 76)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 76)\n",
      "non_zero_slice = 305\n",
      "(256, 536, 66)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 66)\n",
      "non_zero_slice = 268\n",
      "(256, 740, 66)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 66)\n",
      "non_zero_slice = 366\n",
      "(256, 944, 57)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 57)\n",
      "non_zero_slice = 419\n",
      "(256, 638, 99)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 99)\n",
      "non_zero_slice = 524\n",
      "(256, 638, 107)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 107)\n",
      "non_zero_slice = 513\n",
      "(256, 536, 98)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 98)\n",
      "non_zero_slice = 412\n",
      "(256, 434, 99)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 99)\n",
      "non_zero_slice = 323\n",
      "(256, 536, 60)\n",
      "0 102 256 128\n",
      "Data_slice_shape = (256, 128, 60)\n",
      "non_zero_slice = 223\n"
     ]
    }
   ],
   "source": [
    "# Only need to run once! \n",
    "for exp in EXP_LIST:\n",
    "    data_slice_KE(RAW_NPY_FOLDER, NPY_FOLDER, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(DATA_FOLDER,ML_exp, G1, G2, split_ratio):\n",
    "    train_combine = []\n",
    "    eval_combine = []\n",
    "    test_combine = []\n",
    "    eval_exp_win_stat = []\n",
    "    test_exp_win_stat = []\n",
    "    train_exp_win_stat = []\n",
    "    for exp in G1:        \n",
    "        fmt = DATA_FOLDER + 'file_master/' + str(exp) + '.txt'\n",
    "        a = np.loadtxt(fmt, dtype=str)       \n",
    "        # for each experiments in G1, we 100% attribute them to training dataset. \n",
    "        train_combine = np.concatenate([train_combine, a])\n",
    "        # housekeeping for the exp/slice included in training\n",
    "        num_win = int(a[-1].split('win_')[-1][0:1])+1\n",
    "        for i in range (num_win):\n",
    "            train_slice = [exp, i]\n",
    "            train_exp_win_stat.append(train_slice)\n",
    "            \n",
    "    for exp in G2:\n",
    "        fmt = DATA_FOLDER + 'file_master/' + str(exp) + '.txt'\n",
    "        b = np.loadtxt(fmt, dtype=str)\n",
    "        #check last element for its window number + 1 to get #of window\n",
    "        num_win = int(b[-1].split('win_')[-1][0:1])+1\n",
    "        #check how many time slice per window \n",
    "        win_len = len(b)/num_win\n",
    "        print(\"num_win\",num_win)\n",
    "        print(\"len_b\",len(b))\n",
    "        #check randomized which slice would be included in \n",
    "        shf_idx = np.arange(num_win)\n",
    "        print(shf_idx)\n",
    "        np.random.shuffle(shf_idx)\n",
    "        print(shf_idx)\n",
    "        \n",
    "        # split_eval = split_ratio\n",
    "        split_eval = num_win//3\n",
    "        \n",
    "        #distribute one random window-slice to eval\n",
    "        for idx in range(split_eval):\n",
    "            eval_ini = int(shf_idx[idx]*win_len)\n",
    "            eval_end = int((shf_idx[idx]+1)*win_len)\n",
    "            eval_combine = np.concatenate([eval_combine,  b[eval_ini:eval_end]])\n",
    "            # housekeeping for the exp/slice included in evaluating\n",
    "            eval_slice = [exp,shf_idx[idx]] \n",
    "            eval_exp_win_stat.append(eval_slice)\n",
    "                \n",
    "        #distribute one random window-slice to test\n",
    "        test_ini = int(shf_idx[split_eval]*win_len)\n",
    "        test_end = int((shf_idx[split_eval]+1)*win_len)\n",
    "        test_combine = np.concatenate([test_combine,  b[test_ini:test_end]])\n",
    "        # houseckeeping for the exp/slice included in testting\n",
    "        test_slice = [exp,shf_idx[split_eval]] \n",
    "        test_exp_win_stat.append(test_slice)\n",
    "        \n",
    "        #distribute the rest of random window-slices to train\n",
    "        for idx in range(split_eval+1,num_win):\n",
    "            train_ini = int(shf_idx[idx]*win_len)\n",
    "            train_end = int((shf_idx[idx]+1)*win_len)\n",
    "            train_combine = np.concatenate([train_combine, b[train_ini:train_end]])\n",
    "            # houseckeeping for the exp/slice included in training\n",
    "            train_slice = [exp,shf_idx[idx]] \n",
    "            train_exp_win_stat.append(train_slice)\n",
    "            \n",
    "    tot_dataset = len(train_combine) + len(eval_combine) + len(test_combine)\n",
    "    train_ratio = format(len(train_combine)/tot_dataset, '.2f')\n",
    "    eval_ratio = format(len(eval_combine)/tot_dataset, '.2f')\n",
    "    test_ratio = format(len(test_combine)/tot_dataset, '.2f')\n",
    "    \n",
    "    stat_dict = {'train_ew': train_exp_win_stat,\n",
    "                'eval_ew': eval_exp_win_stat,\n",
    "                'test_ew': test_exp_win_stat,\n",
    "                'tot_dataset':tot_dataset,\n",
    "                'train_ratio':train_ratio,\n",
    "                'eval_ratio':eval_ratio,\n",
    "                'test_ratio':test_ratio}\n",
    "    print(stat_dict)\n",
    "    ML_EXP_PATH = DATA_FOLDER + str(ML_exp)\n",
    "    if not os.path.exists(ML_EXP_PATH): \n",
    "        os.makedirs(ML_EXP_PATH)\n",
    "    \n",
    "    with open(ML_EXP_PATH +'/data_stat.txt', 'w') as f:\n",
    "        print(stat_dict, file=f)\n",
    "        \n",
    "    train_data_path = ML_EXP_PATH +  '/train_master.txt'\n",
    "    np.savetxt(train_data_path, train_combine, fmt=\"%s\")\n",
    "    \n",
    "    eval_data_path = ML_EXP_PATH +  '/eval_master.txt'\n",
    "    np.savetxt(eval_data_path, eval_combine, fmt=\"%s\")\n",
    "    \n",
    "    test_data_path = ML_EXP_PATH +  '/test_master.txt'\n",
    "    np.savetxt(test_data_path, test_combine, fmt=\"%s\")\n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_win 4\n",
      "len_b 259\n",
      "[0 1 2 3]\n",
      "[2 1 3 0]\n",
      "num_win 3\n",
      "len_b 857\n",
      "[0 1 2]\n",
      "[0 2 1]\n",
      "num_win 2\n",
      "len_b 474\n",
      "[0 1]\n",
      "[0 1]\n",
      "num_win 5\n",
      "len_b 305\n",
      "[0 1 2 3 4]\n",
      "[4 2 1 3 0]\n",
      "num_win 10\n",
      "len_b 503\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 6 5 3 9 2 7 1 8 4]\n",
      "num_win 4\n",
      "len_b 283\n",
      "[0 1 2 3]\n",
      "[0 1 3 2]\n",
      "num_win 3\n",
      "len_b 949\n",
      "[0 1 2]\n",
      "[0 2 1]\n",
      "num_win 2\n",
      "len_b 504\n",
      "[0 1]\n",
      "[0 1]\n",
      "num_win 9\n",
      "len_b 419\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[7 1 2 0 5 4 6 3 8]\n",
      "num_win 5\n",
      "len_b 268\n",
      "[0 1 2 3 4]\n",
      "[2 1 4 3 0]\n",
      "num_win 7\n",
      "len_b 366\n",
      "[0 1 2 3 4 5 6]\n",
      "[6 2 1 0 5 3 4]\n",
      "num_win 6\n",
      "len_b 524\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 5 4 3]\n",
      "num_win 5\n",
      "len_b 412\n",
      "[0 1 2 3 4]\n",
      "[2 3 1 4 0]\n",
      "num_win 4\n",
      "len_b 323\n",
      "[0 1 2 3]\n",
      "[2 0 3 1]\n",
      "num_win 5\n",
      "len_b 223\n",
      "[0 1 2 3 4]\n",
      "[1 2 0 3 4]\n",
      "{'train_ew': [['E280_128px_forCNN', 0], ['E280_128px_forCNN', 1], ['E280_128px_forCNN', 2], ['E280_128px_forCNN', 3], ['E280_128px_forCNN', 4], ['E280_128px_forCNN', 5], ['E280_128px_forCNN', 6], ['E339_128px_forCNN', 0], ['E339_128px_forCNN', 1], ['E339_128px_forCNN', 2], ['E339_128px_forCNN', 3], ['E339_128px_forCNN', 4], ['E339_128px_forCNN', 5], ['E339_128px_forCNN', 6], ['E339_128px_forCNN', 7], ['E339_128px_forCNN', 8], ['E347_128px_forCNN', 0], ['E347_128px_forCNN', 1], ['E347_128px_forCNN', 2], ['E347_128px_forCNN', 3], ['E347_128px_forCNN', 4], ['E365_128px_forCNN', 0], ['E365_128px_forCNN', 1], ['E459_128px_forCNN', 0], ['E459_128px_forCNN', 1], ['E459_128px_forCNN', 2], ['E459_128px_forCNN', 3], ['E459_128px_forCNN', 4], ['E459_128px_forCNN', 5], ['E338_128px_forCNN', 3], ['E338_128px_forCNN', 0], ['E341_128px_forCNN', 1], ['E342_128px_forCNN', 1], ['E345_128px_forCNN', 1], ['E345_128px_forCNN', 3], ['E345_128px_forCNN', 0], ['E346_128px_forCNN', 9], ['E346_128px_forCNN', 2], ['E346_128px_forCNN', 7], ['E346_128px_forCNN', 1], ['E346_128px_forCNN', 8], ['E346_128px_forCNN', 4], ['E355_128px_forCNN', 3], ['E355_128px_forCNN', 2], ['E364_128px_forCNN', 1], ['E366_128px_forCNN', 1], ['E369_128px_forCNN', 5], ['E369_128px_forCNN', 4], ['E369_128px_forCNN', 6], ['E369_128px_forCNN', 3], ['E369_128px_forCNN', 8], ['E363_128px_forCNN', 4], ['E363_128px_forCNN', 3], ['E363_128px_forCNN', 0], ['E368_128px_forCNN', 0], ['E368_128px_forCNN', 5], ['E368_128px_forCNN', 3], ['E368_128px_forCNN', 4], ['E458_128px_forCNN', 5], ['E458_128px_forCNN', 4], ['E458_128px_forCNN', 3], ['E463_128px_forCNN', 1], ['E463_128px_forCNN', 4], ['E463_128px_forCNN', 0], ['E464_128px_forCNN', 3], ['E464_128px_forCNN', 1], ['E499_128px_forCNN', 0], ['E499_128px_forCNN', 3], ['E499_128px_forCNN', 4]], 'eval_ew': [['E338_128px_forCNN', 2], ['E341_128px_forCNN', 0], ['E345_128px_forCNN', 4], ['E346_128px_forCNN', 0], ['E346_128px_forCNN', 6], ['E346_128px_forCNN', 5], ['E355_128px_forCNN', 0], ['E364_128px_forCNN', 0], ['E369_128px_forCNN', 7], ['E369_128px_forCNN', 1], ['E369_128px_forCNN', 2], ['E363_128px_forCNN', 2], ['E368_128px_forCNN', 6], ['E368_128px_forCNN', 2], ['E458_128px_forCNN', 0], ['E458_128px_forCNN', 1], ['E463_128px_forCNN', 2], ['E464_128px_forCNN', 2], ['E499_128px_forCNN', 1]], 'test_ew': [['E338_128px_forCNN', 1], ['E341_128px_forCNN', 2], ['E342_128px_forCNN', 0], ['E345_128px_forCNN', 2], ['E346_128px_forCNN', 3], ['E355_128px_forCNN', 1], ['E364_128px_forCNN', 2], ['E366_128px_forCNN', 0], ['E369_128px_forCNN', 0], ['E363_128px_forCNN', 1], ['E368_128px_forCNN', 1], ['E458_128px_forCNN', 2], ['E463_128px_forCNN', 3], ['E464_128px_forCNN', 0], ['E499_128px_forCNN', 2]], 'tot_dataset': 8690, 'train_ratio': '0.61', 'eval_ratio': '0.19', 'test_ratio': '0.21'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_ew': [['E280_128px_forCNN', 0],\n",
       "  ['E280_128px_forCNN', 1],\n",
       "  ['E280_128px_forCNN', 2],\n",
       "  ['E280_128px_forCNN', 3],\n",
       "  ['E280_128px_forCNN', 4],\n",
       "  ['E280_128px_forCNN', 5],\n",
       "  ['E280_128px_forCNN', 6],\n",
       "  ['E339_128px_forCNN', 0],\n",
       "  ['E339_128px_forCNN', 1],\n",
       "  ['E339_128px_forCNN', 2],\n",
       "  ['E339_128px_forCNN', 3],\n",
       "  ['E339_128px_forCNN', 4],\n",
       "  ['E339_128px_forCNN', 5],\n",
       "  ['E339_128px_forCNN', 6],\n",
       "  ['E339_128px_forCNN', 7],\n",
       "  ['E339_128px_forCNN', 8],\n",
       "  ['E347_128px_forCNN', 0],\n",
       "  ['E347_128px_forCNN', 1],\n",
       "  ['E347_128px_forCNN', 2],\n",
       "  ['E347_128px_forCNN', 3],\n",
       "  ['E347_128px_forCNN', 4],\n",
       "  ['E365_128px_forCNN', 0],\n",
       "  ['E365_128px_forCNN', 1],\n",
       "  ['E459_128px_forCNN', 0],\n",
       "  ['E459_128px_forCNN', 1],\n",
       "  ['E459_128px_forCNN', 2],\n",
       "  ['E459_128px_forCNN', 3],\n",
       "  ['E459_128px_forCNN', 4],\n",
       "  ['E459_128px_forCNN', 5],\n",
       "  ['E338_128px_forCNN', 3],\n",
       "  ['E338_128px_forCNN', 0],\n",
       "  ['E341_128px_forCNN', 1],\n",
       "  ['E342_128px_forCNN', 1],\n",
       "  ['E345_128px_forCNN', 1],\n",
       "  ['E345_128px_forCNN', 3],\n",
       "  ['E345_128px_forCNN', 0],\n",
       "  ['E346_128px_forCNN', 9],\n",
       "  ['E346_128px_forCNN', 2],\n",
       "  ['E346_128px_forCNN', 7],\n",
       "  ['E346_128px_forCNN', 1],\n",
       "  ['E346_128px_forCNN', 8],\n",
       "  ['E346_128px_forCNN', 4],\n",
       "  ['E355_128px_forCNN', 3],\n",
       "  ['E355_128px_forCNN', 2],\n",
       "  ['E364_128px_forCNN', 1],\n",
       "  ['E366_128px_forCNN', 1],\n",
       "  ['E369_128px_forCNN', 5],\n",
       "  ['E369_128px_forCNN', 4],\n",
       "  ['E369_128px_forCNN', 6],\n",
       "  ['E369_128px_forCNN', 3],\n",
       "  ['E369_128px_forCNN', 8],\n",
       "  ['E363_128px_forCNN', 4],\n",
       "  ['E363_128px_forCNN', 3],\n",
       "  ['E363_128px_forCNN', 0],\n",
       "  ['E368_128px_forCNN', 0],\n",
       "  ['E368_128px_forCNN', 5],\n",
       "  ['E368_128px_forCNN', 3],\n",
       "  ['E368_128px_forCNN', 4],\n",
       "  ['E458_128px_forCNN', 5],\n",
       "  ['E458_128px_forCNN', 4],\n",
       "  ['E458_128px_forCNN', 3],\n",
       "  ['E463_128px_forCNN', 1],\n",
       "  ['E463_128px_forCNN', 4],\n",
       "  ['E463_128px_forCNN', 0],\n",
       "  ['E464_128px_forCNN', 3],\n",
       "  ['E464_128px_forCNN', 1],\n",
       "  ['E499_128px_forCNN', 0],\n",
       "  ['E499_128px_forCNN', 3],\n",
       "  ['E499_128px_forCNN', 4]],\n",
       " 'eval_ew': [['E338_128px_forCNN', 2],\n",
       "  ['E341_128px_forCNN', 0],\n",
       "  ['E345_128px_forCNN', 4],\n",
       "  ['E346_128px_forCNN', 0],\n",
       "  ['E346_128px_forCNN', 6],\n",
       "  ['E346_128px_forCNN', 5],\n",
       "  ['E355_128px_forCNN', 0],\n",
       "  ['E364_128px_forCNN', 0],\n",
       "  ['E369_128px_forCNN', 7],\n",
       "  ['E369_128px_forCNN', 1],\n",
       "  ['E369_128px_forCNN', 2],\n",
       "  ['E363_128px_forCNN', 2],\n",
       "  ['E368_128px_forCNN', 6],\n",
       "  ['E368_128px_forCNN', 2],\n",
       "  ['E458_128px_forCNN', 0],\n",
       "  ['E458_128px_forCNN', 1],\n",
       "  ['E463_128px_forCNN', 2],\n",
       "  ['E464_128px_forCNN', 2],\n",
       "  ['E499_128px_forCNN', 1]],\n",
       " 'test_ew': [['E338_128px_forCNN', 1],\n",
       "  ['E341_128px_forCNN', 2],\n",
       "  ['E342_128px_forCNN', 0],\n",
       "  ['E345_128px_forCNN', 2],\n",
       "  ['E346_128px_forCNN', 3],\n",
       "  ['E355_128px_forCNN', 1],\n",
       "  ['E364_128px_forCNN', 2],\n",
       "  ['E366_128px_forCNN', 0],\n",
       "  ['E369_128px_forCNN', 0],\n",
       "  ['E363_128px_forCNN', 1],\n",
       "  ['E368_128px_forCNN', 1],\n",
       "  ['E458_128px_forCNN', 2],\n",
       "  ['E463_128px_forCNN', 3],\n",
       "  ['E464_128px_forCNN', 0],\n",
       "  ['E499_128px_forCNN', 2]],\n",
       " 'tot_dataset': 8690,\n",
       " 'train_ratio': '0.61',\n",
       " 'eval_ratio': '0.19',\n",
       " 'test_ratio': '0.21'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if EXPERIMENT == \"clay\":\n",
    "    G1 = ['EB_025_1', 'EB_050_1', 'EB_150_1','PP_025_1','PP_050_1','PP_100_1']\n",
    "    G2 = ['EB_025_2', 'EB_025_3', 'EB_050_2','EB_050_3','EB_150_2','EB_150_3','PP_025_2','PP_050_2','PP_100_2' ]\n",
    "    create_dataset(NPY_FOLDER, ML_exp, G1, G2,split_ratio)\n",
    "elif EXPERIMENT == \"sand\":\n",
    "    G1 = ['E280_64px_forCNN',\n",
    "    'E339_64px_forCNN',\n",
    "    'E347_64px_forCNN',\n",
    "    'E365_64px_forCNN',\n",
    "    'E459_64px_forCNN']\n",
    "\n",
    "    G2 = ['E338_64px_forCNN',\n",
    "    'E341_64px_forCNN',\n",
    "    'E342_64px_forCNN',\n",
    "    'E345_64px_forCNN',\n",
    "    'E346_64px_forCNN',\n",
    "    'E355_64px_forCNN',\n",
    "    'E364_64px_forCNN',\n",
    "    'E366_64px_forCNN',\n",
    "    'E369_64px_forCNN',\n",
    "    'E363_64px_forCNN',\n",
    "    'E368_64px_forCNN',\n",
    "    'E458_64px_forCNN',\n",
    "    'E463_64px_forCNN',\n",
    "    'E464_64px_forCNN',\n",
    "    'E499_64px_forCNN']\n",
    "else:\n",
    "    G1 = ['E280_128px_forCNN',\n",
    "    'E339_128px_forCNN',\n",
    "    'E347_128px_forCNN',\n",
    "    'E365_128px_forCNN',\n",
    "    'E459_128px_forCNN']\n",
    "\n",
    "    G2 = ['E338_128px_forCNN',\n",
    "    'E341_128px_forCNN',\n",
    "    'E342_128px_forCNN',\n",
    "    'E345_128px_forCNN',\n",
    "    'E346_128px_forCNN',\n",
    "    'E355_128px_forCNN',\n",
    "    'E364_128px_forCNN',\n",
    "    'E366_128px_forCNN',\n",
    "    'E369_128px_forCNN',\n",
    "    'E363_128px_forCNN',\n",
    "    'E368_128px_forCNN',\n",
    "    'E458_128px_forCNN',\n",
    "    'E463_128px_forCNN',\n",
    "    'E464_128px_forCNN',\n",
    "    'E499_128px_forCNN']\n",
    "\n",
    "create_dataset(NPY_FOLDER, ML_exp, G1, G2,split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5b869f9e4e23c26c27a4c0697de3e6b12f69bb347bea3ec85fb04f0bb147111"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('nn682')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
