{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update dataset name as needed\n",
    "\n",
    "EXPERIMENT = \"sand\"\n",
    "# EXPERIMENT = \"clay\"\n",
    "\n",
    "# RAW_DATA_FOLDER_CLAY = '../'\n",
    "# RAW_MAT_FOLDER_CLAY = RAW_DATA_FOLDER_CLAY + 'raw_mat_new_clay/'\n",
    "# RAW_NPY_FOLDER_CLAY = RAW_DATA_FOLDER_CLAY + 'raw_npy_clay/'\n",
    "# NPY_FOLDER_CLAY = '../processed_input_data_clay/'\n",
    "\n",
    "RAW_DATA_FOLDER = '../'\n",
    "RAW_MAT_FOLDER = RAW_DATA_FOLDER + 'raw_mat_new_' + EXPERIMENT + '/'\n",
    "RAW_NPY_FOLDER = RAW_DATA_FOLDER + 'raw_npy_' + EXPERIMENT + '/'\n",
    "NPY_FOLDER = '../processed_input_data_' + EXPERIMENT + '/'\n",
    "\n",
    "#split data\n",
    "## attribute all exp_1 to training\n",
    "## attribute 2 windows (split_ratio) from exp_2 and exp_3 to training\n",
    "## the rest were randomly used for either eval and train. \n",
    "ML_exp = 'split_master'\n",
    "split_ratio=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXP_LIST contains a list of raw experiment XXX.mat files \n",
    "#Format: raw .mat --> raw .npy --> sliced & labeled .npy \n",
    "\n",
    "if EXPERIMENT == \"clay\":\n",
    "# Experiments list for Clay\n",
    "    EXP_LIST = ['EB_025_1','EB_025_2','EB_025_3',\n",
    "            'EB_050_1','EB_050_2','EB_050_3',\n",
    "            'EB_150_1','EB_150_2','EB_150_3',\n",
    "            'PP_025_1','PP_025_2',\n",
    "            'PP_050_1','PP_050_2',\n",
    "            'PP_100_1','PP_100_2',\n",
    "            'PP_150_1']\n",
    "else:\n",
    "# Experiments list for Sand\n",
    "    EXP_LIST = ['E355_64px_forCNN',\n",
    "    'E339_64px_forCNN',\n",
    "    'E280_64px_forCNN',\n",
    "    'E366_64px_forCNN',\n",
    "    'E342_64px_forCNN',\n",
    "    'E340_64px_forCNN',\n",
    "    'E364_64px_forCNN',\n",
    "    'E347_64px_forCNN',\n",
    "    'E346_64px_forCNN',\n",
    "    'E341_64px_forCNN',\n",
    "    'E365_64px_forCNN',\n",
    "    'E338_64px_forCNN',\n",
    "    'E345_64px_forCNN',\n",
    "    'E363_64px_forCNN',\n",
    "    'E368_64px_forCNN',\n",
    "    'E369_64px_forCNN',\n",
    "    'E458_64px_forCNN',\n",
    "    'E459_64px_forCNN',\n",
    "    'E463_64px_forCNN',\n",
    "    'E464_64px_forCNN',\n",
    "    'E499_64px_forCNN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functions to generate.npy files from mat files \n",
    "\n",
    "\n",
    "def create_npy(exp):\n",
    "    matlab_data_path = RAW_MAT_FOLDER + str(exp) + '.mat' \n",
    "    npy_data_path = RAW_NPY_FOLDER + str(exp) +'data.npy'\n",
    "    npy_label_path = RAW_NPY_FOLDER + str(exp) +'label.npy'\n",
    "    npy_para_path = RAW_NPY_FOLDER + str(exp) +'para.npy'\n",
    "    \n",
    "    if not os.path.exists(RAW_NPY_FOLDER):\n",
    "        os.mkdir(RAW_NPY_FOLDER)\n",
    "    if os.path.exists(npy_data_path):\n",
    "        raise Exception(\"raw .npy file already exist\")\n",
    "    else:  \n",
    "        data = sio.loadmat(matlab_data_path) [\"fault_map\"]  \n",
    "        label = sio.loadmat(matlab_data_path) [\"label\"]\n",
    "        \n",
    "        WW = sio.loadmat(matlab_data_path) [\"windowWidth\"]\n",
    "        overlap = sio.loadmat(matlab_data_path) [\"overlap\"]\n",
    "        \n",
    "        slice_param = [0 for a in range(4)]\n",
    "        slice_param[3] = WW[0,0]\n",
    "        slice_param[2] = 2* slice_param[3]\n",
    "        slice_param[1] = slice_param[3]- overlap[0,0]\n",
    "        slice_param[0] = 0\n",
    "        \n",
    "        # report sizes and save data, parameters and label\n",
    "        print(data.shape)\n",
    "        print(label.shape)\n",
    "        print(slice_param)\n",
    "        np.save(npy_data_path, data)\n",
    "        np.save(npy_label_path, label)\n",
    "        np.save(npy_para_path, slice_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E355_64px_forCNN\n",
      "(128, 214, 79)\n",
      "(4, 79, 2)\n",
      "[0, 50, 128, 64]\n",
      "E339_64px_forCNN\n",
      "(128, 464, 63)\n",
      "(9, 63, 2)\n",
      "[0, 50, 128, 64]\n",
      "E280_64px_forCNN\n",
      "(128, 414, 61)\n",
      "(8, 61, 2)\n",
      "[0, 50, 128, 64]\n",
      "E366_64px_forCNN\n",
      "(128, 814, 42)\n",
      "(16, 42, 2)\n",
      "[0, 50, 128, 64]\n",
      "E342_64px_forCNN\n",
      "(128, 814, 42)\n",
      "(16, 42, 2)\n",
      "[0, 50, 128, 64]\n",
      "E340_64px_forCNN\n",
      "(128, 614, 55)\n",
      "(12, 55, 2)\n",
      "[0, 50, 128, 64]\n",
      "E364_64px_forCNN\n",
      "(128, 1264, 48)\n",
      "(25, 48, 2)\n",
      "[0, 50, 128, 64]\n",
      "E347_64px_forCNN\n",
      "(128, 264, 62)\n",
      "(5, 62, 2)\n",
      "[0, 50, 128, 64]\n",
      "E346_64px_forCNN\n",
      "(128, 514, 61)\n",
      "(10, 61, 2)\n",
      "[0, 50, 128, 64]\n",
      "E341_64px_forCNN\n",
      "(128, 1214, 49)\n",
      "(24, 49, 2)\n",
      "[0, 50, 128, 64]\n",
      "E365_64px_forCNN\n",
      "(128, 614, 55)\n",
      "(12, 55, 2)\n",
      "[0, 50, 128, 64]\n",
      "E338_64px_forCNN\n",
      "(128, 214, 82)\n",
      "(4, 82, 2)\n",
      "[0, 50, 128, 64]\n",
      "E345_64px_forCNN\n",
      "(128, 264, 76)\n",
      "(5, 76, 2)\n",
      "[0, 50, 128, 64]\n",
      "E363_64px_forCNN\n",
      "(128, 264, 66)\n",
      "(5, 66, 2)\n",
      "[0, 50, 128, 64]\n",
      "E368_64px_forCNN\n",
      "(128, 364, 66)\n",
      "(7, 66, 2)\n",
      "[0, 50, 128, 64]\n",
      "E369_64px_forCNN\n",
      "(128, 464, 58)\n",
      "(9, 58, 2)\n",
      "[0, 50, 128, 64]\n",
      "E458_64px_forCNN\n",
      "(128, 314, 99)\n",
      "(6, 99, 2)\n",
      "[0, 50, 128, 64]\n",
      "E459_64px_forCNN\n",
      "(128, 314, 107)\n",
      "(6, 107, 2)\n",
      "[0, 50, 128, 64]\n",
      "E463_64px_forCNN\n",
      "(128, 264, 98)\n",
      "(5, 98, 2)\n",
      "[0, 50, 128, 64]\n",
      "E464_64px_forCNN\n",
      "(128, 214, 99)\n",
      "(4, 99, 2)\n",
      "[0, 50, 128, 64]\n",
      "E499_64px_forCNN\n",
      "(128, 264, 90)\n",
      "(5, 90, 2)\n",
      "[0, 50, 128, 64]\n"
     ]
    }
   ],
   "source": [
    "# Generate and save raw_npy for list of experiment\n",
    "# Only need to run once! \n",
    "\n",
    "for e in EXP_LIST:\n",
    "    print(e)\n",
    "    create_npy(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function creates slices of each fault map\n",
    "def slicing_hw(RAW_NPY_FOLDER, exp): \n",
    "    npy_data_path = RAW_NPY_FOLDER + str(exp) +'data.npy'\n",
    "    npy_para_path = RAW_NPY_FOLDER + str(exp) +'para.npy'\n",
    "    \n",
    "    data = np.load(npy_data_path)\n",
    "    print(data.shape)\n",
    "    slice_param = np.load(npy_para_path)\n",
    "    \n",
    "    #data has dimension of (x, y, cfuv, t)\n",
    "    width_tot = data.shape[1]\n",
    "    t_tot = data.shape[2]\n",
    "    #print(width_tot,t_tot)\n",
    "    \n",
    "    #unpack slice_param into initial_index, strike_lenght, window_H and window_W\n",
    "    ii = slice_param[0]\n",
    "    strike = slice_param[1]\n",
    "    H = slice_param[2]\n",
    "    W = slice_param[3]\n",
    "    print(ii,strike,H,W)\n",
    "    \n",
    "    # set number of windows and slice data and label \n",
    "    num_win = 1 + (width_tot - W)//strike   \n",
    "    \n",
    "    data_hw = []\n",
    "    w_idx = np.arange(num_win)\n",
    "    for w_i in w_idx:\n",
    "        left_win = w_i*strike\n",
    "        #print(left_win)\n",
    "        data_hwi = data[:,left_win:left_win+W]\n",
    "        #data_hw is a list of tuples (number of tuples = num_win)\n",
    "        #first element of tuple has a shape = (WindowHeight, WindowWidth, numFrames)\n",
    "        #second element of tuple is the w_idx\n",
    "        data_hw.append((data_hwi, w_i))\n",
    "\n",
    "    print(\"Data_slice_shape =\", data_hw[0][0].shape)\n",
    "    return data_hw, num_win, t_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function gathers the label information and saves with slices to be read for dividing into \n",
    "#training, eval and testing data sets.\n",
    "def data_slice_KE(RAW_NPY_FOLDER, NPY_FOLDER, exp):\n",
    "    \n",
    "    #set file location for \n",
    "    npy_exp_folder_path = NPY_FOLDER + 'slice_npy/' + str(exp)\n",
    "    master_folder_path = NPY_FOLDER + 'file_master/'\n",
    "    \n",
    "    #need to grab the KE labels\n",
    "    npy_label_path = RAW_NPY_FOLDER + str(exp) +'label.npy'\n",
    "    label = np.load(npy_label_path)\n",
    "    #print('label', label.shape)\n",
    "    \n",
    "    if os.path.exists(npy_exp_folder_path):\n",
    "        raise Exception(\"slice_exp.npy already exist\")\n",
    "    else: \n",
    "        os.makedirs(npy_exp_folder_path)\n",
    "        if not os.path.exists(master_folder_path): \n",
    "            os.makedirs(master_folder_path)     \n",
    "    \n",
    "    #slice the fault_map\n",
    "    data_hw, num_win, t_tot = slicing_hw(RAW_NPY_FOLDER, exp)\n",
    "    \n",
    "    w_idx = np.arange(num_win)\n",
    "    file_master = []\n",
    "    \n",
    "    #looping through all windows and times \n",
    "    for w_i in w_idx: \n",
    "        for t_i in range(t_tot):\n",
    "            #unpacking data_hw\n",
    "            data_f, win = data_hw[w_i]\n",
    "            #print(win)\n",
    "        \n",
    "            #only process slice with non-zero fault traces\n",
    "            if np.sum(data_f[:,:,t_i]) != 0:\n",
    "                \n",
    "                #The first array of the label array are the KE and the second array is the std\n",
    "                label_KE = label[w_i,t_i,0]\n",
    "                label_SD = label[w_i,t_i,1]\n",
    "                #print(w_i,t_i,label_KE,label_SD)\n",
    "                \n",
    "                name_path = '/' + str(label_KE) + '_' + str(label_SD) + '_win_' + str(\n",
    "                        win) + '_t_' + str('{:03d}'.format(t_i)) + '_' + str(exp) + '_cfuv.npy'\n",
    "                # save sliced and labeled dataset in slice_npy folder\n",
    "                np.save(npy_exp_folder_path + name_path, data_f[:,:,t_i])\n",
    "                \n",
    "                # add to file master\n",
    "                file_master.append(str(exp) + name_path)          \n",
    "    \n",
    "    master_data_path = master_folder_path + str(exp) + \".txt\"\n",
    "    print('non_zero_slice =', len(file_master))\n",
    "    np.savetxt(master_data_path, file_master, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 214, 79)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 79)\n",
      "non_zero_slice = 253\n",
      "(128, 464, 63)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 63)\n",
      "non_zero_slice = 424\n",
      "(128, 414, 61)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 61)\n",
      "non_zero_slice = 374\n",
      "(128, 814, 42)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 42)\n",
      "non_zero_slice = 509\n",
      "(128, 814, 42)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 42)\n",
      "non_zero_slice = 493\n",
      "(128, 614, 55)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 55)\n",
      "non_zero_slice = 500\n",
      "(128, 1264, 48)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 48)\n",
      "non_zero_slice = 950\n",
      "(128, 264, 62)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 62)\n",
      "non_zero_slice = 252\n",
      "(128, 514, 61)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 61)\n",
      "non_zero_slice = 490\n",
      "(128, 1214, 49)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 49)\n",
      "non_zero_slice = 775\n",
      "(128, 614, 55)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 55)\n",
      "non_zero_slice = 533\n",
      "(128, 214, 82)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 82)\n",
      "non_zero_slice = 260\n",
      "(128, 264, 76)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 76)\n",
      "non_zero_slice = 305\n",
      "(128, 264, 66)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 66)\n",
      "non_zero_slice = 261\n",
      "(128, 364, 66)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 66)\n",
      "non_zero_slice = 369\n",
      "(128, 464, 58)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 58)\n",
      "non_zero_slice = 417\n",
      "(128, 314, 99)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 99)\n",
      "non_zero_slice = 495\n",
      "(128, 314, 107)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 107)\n",
      "non_zero_slice = 498\n",
      "(128, 264, 98)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 98)\n",
      "non_zero_slice = 408\n",
      "(128, 214, 99)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 99)\n",
      "non_zero_slice = 321\n",
      "(128, 264, 90)\n",
      "0 50 128 64\n",
      "Data_slice_shape = (128, 64, 90)\n",
      "non_zero_slice = 367\n"
     ]
    }
   ],
   "source": [
    "# Only need to run once! \n",
    "for exp in EXP_LIST:\n",
    "    data_slice_KE(RAW_NPY_FOLDER, NPY_FOLDER, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(DATA_FOLDER,ML_exp, G1, G2, split_ratio):\n",
    "    train_combine = []\n",
    "    eval_combine = []\n",
    "    test_combine = []\n",
    "    eval_exp_win_stat = []\n",
    "    test_exp_win_stat = []\n",
    "    train_exp_win_stat = []\n",
    "    for exp in G1:        \n",
    "        fmt = DATA_FOLDER + 'file_master/' + str(exp) + '.txt'\n",
    "        a = np.loadtxt(fmt, dtype=str)       \n",
    "        # for each experiments in G1, we 100% attribute them to training dataset. \n",
    "        train_combine = np.concatenate([train_combine, a])\n",
    "        # housekeeping for the exp/slice included in training\n",
    "        num_win = int(a[-1].split('win_')[-1][0:1])+1\n",
    "        for i in range (num_win):\n",
    "            train_slice = [exp, i]\n",
    "            train_exp_win_stat.append(train_slice)\n",
    "            \n",
    "    for exp in G2:\n",
    "        fmt = DATA_FOLDER + 'file_master/' + str(exp) + '.txt'\n",
    "        b = np.loadtxt(fmt, dtype=str)\n",
    "        #check last element for its window number + 1 to get #of window\n",
    "        num_win = int(b[-1].split('win_')[-1][0:1])+1\n",
    "        #check how many time slice per window \n",
    "        win_len = len(b)/num_win\n",
    "        print(\"num_win\",num_win)\n",
    "        print(\"len_b\",len(b))\n",
    "        #check randomized which slice would be included in \n",
    "        shf_idx = np.arange(num_win)\n",
    "        print(shf_idx)\n",
    "        np.random.shuffle(shf_idx)\n",
    "        print(shf_idx)\n",
    "        \n",
    "        # split_eval = split_ratio\n",
    "        split_eval = num_win//3\n",
    "        \n",
    "        #distribute one random window-slice to eval\n",
    "        for idx in range(split_eval):\n",
    "            eval_ini = int(shf_idx[idx]*win_len)\n",
    "            eval_end = int((shf_idx[idx]+1)*win_len)\n",
    "            eval_combine = np.concatenate([eval_combine,  b[eval_ini:eval_end]])\n",
    "            # housekeeping for the exp/slice included in evaluating\n",
    "            eval_slice = [exp,shf_idx[idx]] \n",
    "            eval_exp_win_stat.append(eval_slice)\n",
    "                \n",
    "        #distribute one random window-slice to test\n",
    "        test_ini = int(shf_idx[split_eval]*win_len)\n",
    "        test_end = int((shf_idx[split_eval]+1)*win_len)\n",
    "        test_combine = np.concatenate([test_combine,  b[test_ini:test_end]])\n",
    "        # houseckeeping for the exp/slice included in testting\n",
    "        test_slice = [exp,shf_idx[split_eval]] \n",
    "        test_exp_win_stat.append(test_slice)\n",
    "        \n",
    "        #distribute the rest of random window-slices to train\n",
    "        for idx in range(split_eval+1,num_win):\n",
    "            train_ini = int(shf_idx[idx]*win_len)\n",
    "            train_end = int((shf_idx[idx]+1)*win_len)\n",
    "            train_combine = np.concatenate([train_combine, b[train_ini:train_end]])\n",
    "            # houseckeeping for the exp/slice included in training\n",
    "            train_slice = [exp,shf_idx[idx]] \n",
    "            train_exp_win_stat.append(train_slice)\n",
    "            \n",
    "    tot_dataset = len(train_combine) + len(eval_combine) + len(test_combine)\n",
    "    train_ratio = format(len(train_combine)/tot_dataset, '.2f')\n",
    "    eval_ratio = format(len(eval_combine)/tot_dataset, '.2f')\n",
    "    test_ratio = format(len(test_combine)/tot_dataset, '.2f')\n",
    "    \n",
    "    stat_dict = {'train_ew': train_exp_win_stat,\n",
    "                'eval_ew': eval_exp_win_stat,\n",
    "                'test_ew': test_exp_win_stat,\n",
    "                'tot_dataset':tot_dataset,\n",
    "                'train_ratio':train_ratio,\n",
    "                'eval_ratio':eval_ratio,\n",
    "                'test_ratio':test_ratio}\n",
    "    print(stat_dict)\n",
    "    ML_EXP_PATH = DATA_FOLDER + str(ML_exp)\n",
    "    if not os.path.exists(ML_EXP_PATH): \n",
    "        os.makedirs(ML_EXP_PATH)\n",
    "    \n",
    "    with open(ML_EXP_PATH +'/data_stat.txt', 'w') as f:\n",
    "        print(stat_dict, file=f)\n",
    "        \n",
    "    train_data_path = ML_EXP_PATH +  '/train_master.txt'\n",
    "    np.savetxt(train_data_path, train_combine, fmt=\"%s\")\n",
    "    \n",
    "    eval_data_path = ML_EXP_PATH +  '/eval_master.txt'\n",
    "    np.savetxt(eval_data_path, eval_combine, fmt=\"%s\")\n",
    "    \n",
    "    test_data_path = ML_EXP_PATH +  '/test_master.txt'\n",
    "    np.savetxt(test_data_path, test_combine, fmt=\"%s\")\n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_win 4\n",
      "len_b 260\n",
      "[0 1 2 3]\n",
      "[1 2 3 0]\n",
      "num_win 3\n",
      "len_b 775\n",
      "[0 1 2]\n",
      "[0 2 1]\n",
      "num_win 2\n",
      "len_b 493\n",
      "[0 1]\n",
      "[1 0]\n",
      "num_win 5\n",
      "len_b 305\n",
      "[0 1 2 3 4]\n",
      "[4 3 2 0 1]\n",
      "num_win 10\n",
      "len_b 490\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[9 4 3 8 2 0 7 5 1 6]\n",
      "num_win 4\n",
      "len_b 253\n",
      "[0 1 2 3]\n",
      "[2 0 1 3]\n",
      "num_win 3\n",
      "len_b 950\n",
      "[0 1 2]\n",
      "[1 0 2]\n",
      "num_win 2\n",
      "len_b 509\n",
      "[0 1]\n",
      "[1 0]\n",
      "num_win 9\n",
      "len_b 417\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[7 2 5 1 8 6 3 0 4]\n",
      "num_win 5\n",
      "len_b 261\n",
      "[0 1 2 3 4]\n",
      "[1 3 4 0 2]\n",
      "num_win 7\n",
      "len_b 369\n",
      "[0 1 2 3 4 5 6]\n",
      "[1 6 5 2 3 0 4]\n",
      "num_win 6\n",
      "len_b 495\n",
      "[0 1 2 3 4 5]\n",
      "[4 3 5 0 1 2]\n",
      "num_win 5\n",
      "len_b 408\n",
      "[0 1 2 3 4]\n",
      "[4 2 0 3 1]\n",
      "num_win 4\n",
      "len_b 321\n",
      "[0 1 2 3]\n",
      "[1 0 2 3]\n",
      "num_win 5\n",
      "len_b 367\n",
      "[0 1 2 3 4]\n",
      "[1 4 3 2 0]\n",
      "{'train_ew': [['E280_64px_forCNN', 0], ['E280_64px_forCNN', 1], ['E280_64px_forCNN', 2], ['E280_64px_forCNN', 3], ['E280_64px_forCNN', 4], ['E280_64px_forCNN', 5], ['E280_64px_forCNN', 6], ['E280_64px_forCNN', 7], ['E339_64px_forCNN', 0], ['E339_64px_forCNN', 1], ['E339_64px_forCNN', 2], ['E339_64px_forCNN', 3], ['E339_64px_forCNN', 4], ['E339_64px_forCNN', 5], ['E339_64px_forCNN', 6], ['E339_64px_forCNN', 7], ['E339_64px_forCNN', 8], ['E347_64px_forCNN', 0], ['E347_64px_forCNN', 1], ['E347_64px_forCNN', 2], ['E347_64px_forCNN', 3], ['E347_64px_forCNN', 4], ['E365_64px_forCNN', 0], ['E365_64px_forCNN', 1], ['E459_64px_forCNN', 0], ['E459_64px_forCNN', 1], ['E459_64px_forCNN', 2], ['E459_64px_forCNN', 3], ['E459_64px_forCNN', 4], ['E459_64px_forCNN', 5], ['E338_64px_forCNN', 3], ['E338_64px_forCNN', 0], ['E341_64px_forCNN', 1], ['E342_64px_forCNN', 0], ['E345_64px_forCNN', 2], ['E345_64px_forCNN', 0], ['E345_64px_forCNN', 1], ['E346_64px_forCNN', 2], ['E346_64px_forCNN', 0], ['E346_64px_forCNN', 7], ['E346_64px_forCNN', 5], ['E346_64px_forCNN', 1], ['E346_64px_forCNN', 6], ['E355_64px_forCNN', 1], ['E355_64px_forCNN', 3], ['E364_64px_forCNN', 2], ['E366_64px_forCNN', 0], ['E369_64px_forCNN', 8], ['E369_64px_forCNN', 6], ['E369_64px_forCNN', 3], ['E369_64px_forCNN', 0], ['E369_64px_forCNN', 4], ['E363_64px_forCNN', 4], ['E363_64px_forCNN', 0], ['E363_64px_forCNN', 2], ['E368_64px_forCNN', 2], ['E368_64px_forCNN', 3], ['E368_64px_forCNN', 0], ['E368_64px_forCNN', 4], ['E458_64px_forCNN', 0], ['E458_64px_forCNN', 1], ['E458_64px_forCNN', 2], ['E463_64px_forCNN', 0], ['E463_64px_forCNN', 3], ['E463_64px_forCNN', 1], ['E464_64px_forCNN', 2], ['E464_64px_forCNN', 3], ['E499_64px_forCNN', 3], ['E499_64px_forCNN', 2], ['E499_64px_forCNN', 0]], 'eval_ew': [['E338_64px_forCNN', 1], ['E341_64px_forCNN', 0], ['E345_64px_forCNN', 4], ['E346_64px_forCNN', 9], ['E346_64px_forCNN', 4], ['E346_64px_forCNN', 3], ['E355_64px_forCNN', 2], ['E364_64px_forCNN', 1], ['E369_64px_forCNN', 7], ['E369_64px_forCNN', 2], ['E369_64px_forCNN', 5], ['E363_64px_forCNN', 1], ['E368_64px_forCNN', 1], ['E368_64px_forCNN', 6], ['E458_64px_forCNN', 4], ['E458_64px_forCNN', 3], ['E463_64px_forCNN', 4], ['E464_64px_forCNN', 1], ['E499_64px_forCNN', 1]], 'test_ew': [['E338_64px_forCNN', 2], ['E341_64px_forCNN', 2], ['E342_64px_forCNN', 1], ['E345_64px_forCNN', 3], ['E346_64px_forCNN', 8], ['E355_64px_forCNN', 0], ['E364_64px_forCNN', 0], ['E366_64px_forCNN', 1], ['E369_64px_forCNN', 1], ['E363_64px_forCNN', 3], ['E368_64px_forCNN', 5], ['E458_64px_forCNN', 5], ['E463_64px_forCNN', 2], ['E464_64px_forCNN', 0], ['E499_64px_forCNN', 4]], 'tot_dataset': 8754, 'train_ratio': '0.61', 'eval_ratio': '0.18', 'test_ratio': '0.20'}\n"
     ]
    }
   ],
   "source": [
    "if EXPERIMENT == \"clay\":\n",
    "    G1 = ['EB_025_1', 'EB_050_1', 'EB_150_1','PP_025_1','PP_050_1','PP_100_1']\n",
    "    G2 = ['EB_025_2', 'EB_025_3', 'EB_050_2','EB_050_3','EB_150_2','EB_150_3','PP_025_2','PP_050_2','PP_100_2' ]\n",
    "    create_dataset(NPY_FOLDER, ML_exp, G1, G2,split_ratio)\n",
    "else:\n",
    "    G1 = ['E280_64px_forCNN',\n",
    "    'E339_64px_forCNN',\n",
    "    'E347_64px_forCNN',\n",
    "    'E365_64px_forCNN',\n",
    "    'E459_64px_forCNN']\n",
    "\n",
    "    G2 = ['E338_64px_forCNN',\n",
    "    'E341_64px_forCNN',\n",
    "    'E342_64px_forCNN',\n",
    "    'E345_64px_forCNN',\n",
    "    'E346_64px_forCNN',\n",
    "    'E355_64px_forCNN',\n",
    "    'E364_64px_forCNN',\n",
    "    'E366_64px_forCNN',\n",
    "    'E369_64px_forCNN',\n",
    "    'E363_64px_forCNN',\n",
    "    'E368_64px_forCNN',\n",
    "    'E458_64px_forCNN',\n",
    "    'E463_64px_forCNN',\n",
    "    'E464_64px_forCNN',\n",
    "    'E499_64px_forCNN']\n",
    "    create_dataset(NPY_FOLDER, ML_exp, G1, G2,split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
