{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sklearn\n",
    "import tensorflow.keras.backend as kb\n",
    "import yaml\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HelperFn.ExpData_Generator import TrainingGenerator\n",
    "from HelperFn.ExpData_Generator import EvalTestGenerator\n",
    "from HelperFn.utils import Params\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommended params.json is included in run_1 folder, ready for demo run. \n",
    "# archive_final_run folder contain pre-trained model (best model)\n",
    "mini_EXP_name = 'run_1'\n",
    "exp_folder_path = 'experiments/' + mini_EXP_name\n",
    "\n",
    "DATA_DIR = '../processed_input_data/'\n",
    "NPY_FOLDER = 'slice_npy/'\n",
    "ML_EXP = 'split_master/'\n",
    "Train_Master = 'train_master.txt'\n",
    "Eval_Master = 'eval_master.txt'\n",
    "Test_Master = 'test_master.txt'\n",
    "json_path = os.path.join(exp_folder_path, 'params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(json_path)\n",
    "\n",
    "input_slice_shape = (128,64,1)\n",
    "batch_size = params.batch_size\n",
    "MMT = params.bn_momentum\n",
    "LR = params.learning_rate\n",
    "num_channels = params.num_channels\n",
    "EPOCH = params.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define model\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=input_slice_shape))\n",
    "# channels = [num_channels, num_channels * 2,num_channels * 4 ]\n",
    "channels = [num_channels, num_channels * 2]\n",
    "for c in channels:\n",
    "    model.add(layers.Conv2D(c, 3, padding='same'))\n",
    "    model.add(layers.Conv2D(c, 3, dilation_rate = 2, padding='same'))\n",
    "    model.add(layers.BatchNormalization(momentum=MMT))\n",
    "    model.add(layers.Activation(activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(channels[-1]))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.BatchNormalization(momentum=MMT))\n",
    "model.add(layers.Dense(1, activation='relu'))\n",
    "#summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_wSD_loss(Y_true, KE_pred):\n",
    "    KE_true = Y_true[:, 0]\n",
    "    SD_true = Y_true[:, 1]\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    return mse(Y_true[:, 0], KE_pred)/((Y_true[:, 1])**2+1e-5)\n",
    "\n",
    "def custom_accuracy_2SD(Y_true, KE_pred):\n",
    "    KE_true = Y_true[:, 0]\n",
    "    SD_true = Y_true[:, 1]\n",
    "    KE_pred = KE_pred[:, 0]\n",
    "    C_accuracy = kb.mean(kb.cast(kb.less_equal(kb.abs(KE_pred-KE_true),2*SD_true), dtype = \"float32\"))\n",
    "    return C_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "model.compile(optimizer=opt, loss = MSE_wSD_loss, \n",
    "              metrics=['mse', custom_accuracy_2SD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = exp_folder_path + \"/weights-improvement-{epoch:02d}-{val_custom_accuracy_2SD:.2f}.hdf5\"\n",
    "callbacks = [\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.000001,\n",
    "#                                      patience=5,mode='min'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath, monitor ='val_loss', verbose=1,\n",
    "        save_best_only=True, mode= 'min')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = TrainingGenerator(ML_EXP, NPY_FOLDER, Train_Master, batch_size = batch_size, data_dir=DATA_DIR)\n",
    "validation_generator = EvalTestGenerator(ML_EXP, NPY_FOLDER, Eval_Master, batch_size = batch_size, data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# configure early stopping\n",
    "# fit the model\n",
    "history = model.fit(x=training_generator, epochs=EPOCH,\n",
    "                    validation_data=validation_generator, \n",
    "                    callbacks = callbacks,\n",
    "                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_history = history.history\n",
    "with open (exp_folder_path + \"/raw_history.yaml\", \"w\") as filehandle:\n",
    "    yaml.dump(history.history,filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(exp_folder_path + \"/raw_history.yaml\", \"r\") as filehandle2:\n",
    "    raw_history = yaml.load(filehandle2, Loader = yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = raw_history['val_loss']\n",
    "train_accuracy = raw_history['custom_accuracy_2SD']\n",
    "val_accuracy = raw_history['val_custom_accuracy_2SD']\n",
    "best_model_EPOCH = val_loss.index(min(val_loss)) + 1 \n",
    "selected_history = {}\n",
    "selected_history['Bmodel_EPOCH'] = best_model_EPOCH\n",
    "selected_history['min_val_loss'] =  np.round(min(val_loss),4)\n",
    "selected_history['max_train_accuracy'] =  np.round(max(train_accuracy),4)\n",
    "selected_history['max_val_accuracy'] =  np.round(max(val_accuracy),4)\n",
    "selected_history['Bmodel_train_accuracy'] =  np.round(train_accuracy[val_loss.index(min(val_loss))],4)\n",
    "selected_history['Bmodel_val_accuracy'] = np.round(val_accuracy[val_loss.index(min(val_loss))],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(raw_history['loss'][0:EPOCH])\n",
    "plt.plot(raw_history['val_loss'][0:EPOCH])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.text(0.5, 0.5, mini_EXP_name, \n",
    "         horizontalalignment = 'center', transform=plt.gca().transAxes)\n",
    "plt.legend(['Train','Eval'], loc='upper left')\n",
    "plt.savefig(exp_folder_path  +'/loss_.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(raw_history['custom_accuracy_2SD'][0:EPOCH])\n",
    "plt.plot(raw_history['val_custom_accuracy_2SD'][0:EPOCH])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy_2SD')\n",
    "plt.xlabel('Epoch')\n",
    "plt.text(0.5, 0.5, mini_EXP_name, \n",
    "         horizontalalignment = 'center', transform=plt.gca().transAxes)\n",
    "plt.legend(['Train','Eval'], loc='upper left')\n",
    "plt.savefig(exp_folder_path + '/custom_accuracy_2SD.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(exp_folder_path + '/*.hdf5',  \n",
    "                   recursive = True)\n",
    "saved_model = []\n",
    "for file in files:\n",
    "    print(file.split('/')[-1])\n",
    "    saved_model.append(file.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every epoch that show improving performance will be saved. \n",
    "# weights-improvment-'Epoch'-'Eval_2SD_Accuracy'\n",
    "# 'selectedE' must be updated as 'Epoch' in which 'Eval_2SD_Accuracy' is highest \n",
    "\n",
    "selectedE = 'Epoch#'\n",
    "\n",
    "for file in saved_model:\n",
    "    if file.split('-')[-2][0:2]==str(selectedE):\n",
    "        selected_weights = file\n",
    "print (selected_weights)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = exp_folder_path + '/' + selected_weights \n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\n",
    "    filepath, custom_objects = {\"MSE_wSD_loss\":MSE_wSD_loss, \n",
    "                                \"custom_accuracy_2SD\": custom_accuracy_2SD})\n",
    "# best_model = tf.keras.models.load_model(filepath)\n",
    "# best_model = tf.keras.models.load_model(filepath, custom_objects={\"MSE_wSD_loss\":MSE_wSD_loss})\n",
    "# best_model = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply best model to three subset of data\n",
    "\n",
    "##Training\n",
    "train_generator = EvalTestGenerator(ML_EXP, NPY_FOLDER, Train_Master, \n",
    "                                       batch_size = batch_size, \n",
    "                                       data_dir=DATA_DIR, shuffle = False)\n",
    "train_label = np.hstack([batch[1][:,0] for batch in train_generator])\n",
    "train_SD = np.hstack([batch[1][:,1] for batch in train_generator])\n",
    "train_pred = best_model.predict(x=train_generator)\n",
    "\n",
    "##Validation\n",
    "eval_generator = EvalTestGenerator(ML_EXP, NPY_FOLDER, Eval_Master, \n",
    "                                         batch_size = batch_size, \n",
    "                                         data_dir=DATA_DIR, shuffle = False)\n",
    "eval_label = np.hstack([batch[1][:,0] for batch in eval_generator])\n",
    "eval_SD = np.hstack([batch[1][:,1] for batch in eval_generator])\n",
    "eval_pred = best_model.predict(x=eval_generator)\n",
    "\n",
    "##Testing\n",
    "test_generator = EvalTestGenerator(ML_EXP, NPY_FOLDER, Test_Master, \n",
    "                                   batch_size = batch_size, \n",
    "                                   data_dir=DATA_DIR, shuffle = False)\n",
    "test_label = np.hstack([batch[1][:,0] for batch in test_generator])\n",
    "test_SD = np.hstack([batch[1][:,1] for batch in test_generator])\n",
    "test_pred = best_model.predict(x=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LSP = [train_label,train_SD,train_pred]\n",
    "eval_LSP = [eval_label,eval_SD,eval_pred]\n",
    "test_LSP = [test_label,test_SD,test_pred]\n",
    "generator_LSP = [train_LSP,eval_LSP,test_LSP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_with_TS_V(generator_LSP, mode, selected_EP):\n",
    "    ## make cross plot between prediction and label with highlighted color for subset that meet threashold\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(5,12.5))\n",
    "\n",
    "    for g, m, ax in zip(generator_LSP, mode, axs): \n",
    "        label = g[0]\n",
    "        SD = g[1]\n",
    "        pred = g[2].flatten()\n",
    "#         if len(pred) == len(label):\n",
    "#             print(len(pred))\n",
    "        idx = np.abs(pred-label) > 2*SD\n",
    "        error_pct = np.round(100*np.sum(idx)/len(pred), 2)\n",
    "        \n",
    "\n",
    "        ax.plot(pred, label,'o', label=f'Correct')\n",
    "        ax.plot(pred[idx], label[idx], 'ro', label=f'Incorrect')\n",
    "        ax.plot([0, 1], [0, 1], 'k', alpha=0.2)\n",
    "        ax.set_title(str(m), fontsize = 24)\n",
    "        text_error = '% error (>2SD) = ' +str(error_pct) + '%'\n",
    "        ax.text(0.7, 0.1, text_error, fontsize = 12,\n",
    "                horizontalalignment = 'center', transform=ax.transAxes)\n",
    "        ax.legend(loc='best')\n",
    "        ax.set_ylabel('Truth', fontsize =18)\n",
    "    axs[2].set_xlabel('Prediction', fontsize = 18)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_with_TS_V(generator_LSP, ['Train', 'Eval', 'Test'], selected_EP = selectedE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
